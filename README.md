# LLM Sentiment Analysis of Central Bank Communications

A research project using Large Language Models (LLMs) to analyze sentiment in Federal Reserve and European Central Bank speeches, leveraging OpenAI's Batch API for cost-effective processing at scale.

## üìã Table of Contents

- [Overview](#overview)
- [Project Phases](#project-phases)
- [Current Phase: Phase 1](#phase-1-setup--batch-processing-demo)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [For Beginners](#for-beginners)
- [Cost Estimates](#cost-estimates)
- [Documentation](#documentation)

---

## Overview

### What This Project Does

This project analyzes speeches from central bank officials (Federal Reserve and ECB) to extract:

1. **Hawkish/Dovish Score**: Is the central bank leaning toward tightening (raising rates) or easing (lowering rates)?
2. **Topic Emphasis**: What are they focused on? (inflation, growth, financial stability, labor markets, international issues)
3. **Uncertainty Level**: How confident are they about the economic outlook?
4. **Forward Guidance**: How clearly are they signaling future policy actions?
5. **Market Impact**: What might financial markets do in response?

### Why This Matters

- **For Economics Research**: Better measurement tools for studying central bank communication
- **For Financial Markets**: Automated analysis of policy signals that can move markets
- **For Policy Analysis**: Cross-country comparisons of central bank messaging
- **For Education**: Practical demonstration of LLMs in economic research

### Key Innovation

We use OpenAI's **Batch API** instead of real-time API calls:
- ‚úÖ **50% cost savings** (same quality, half the price)
- ‚úÖ **Processes hundreds of speeches** overnight
- ‚úÖ **No rate limits** - process large datasets at once
- ‚úÖ **Reproducible** - same analysis applied consistently

---

## Project Phases

This project is organized into 5 phases, each building on the previous one:

### ‚úÖ **Phase 1** (Current): Setup & Batch Processing Demo
- Load ECB-FED speeches dataset
- Sample 2 years of data (2022-2023)
- Create batch processing files
- Compare costs: Batch API vs Real-time API

### üîÑ **Phase 2**: Full Dataset Processing
- Apply LLM analysis to complete dataset (1996-2025)
- Validate LLM outputs for accuracy
- Quality checks and error handling

### üìä **Phase 3**: Build Sentiment Indices
- Create time series indices (hawkish/dovish, uncertainty, etc.)
- Aggregate by month/quarter
- Visualize trends over time

### üìà **Phase 4**: Market Correlation Analysis
- Correlate sentiment indices with market variables:
  - Stock market returns (S&P 500, EURO STOXX)
  - Bond yields (10-year Treasury)
  - Exchange rates (USD/EUR)
  - Market volatility (VIX)
- Test combined indices (e.g., uncertainty + hawkishness)
- Compare Fed vs ECB predictive power

### üèÜ **Phase 5**: Benchmark Against Literature
- Compare with published indices (FinBERT-FOMC, dictionary methods)
- Validate against known events (2008 crisis, COVID, 2022 inflation)
- Document findings

Each phase will be completed with a Pull Request (PR) for review before moving to the next.

---

## Phase 1: Setup & Batch Processing Demo

### Goals

1. ‚úÖ Demonstrate the project works end-to-end
2. ‚úÖ Understand costs before processing full dataset
3. ‚úÖ Validate data quality and batch processing setup
4. ‚úÖ Show 50% cost savings from Batch API

### What You'll Get

After running Phase 1, you'll have:

- **Sample dataset**: 2 years of central bank speeches (2022-2023)
- **Batch file**: Ready to upload to OpenAI (but not submitted yet)
- **Cost estimates**: Exact costs for both Batch and Real-time API
- **Validation**: Confirmation that everything is set up correctly

### Files Created

```
data/
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ sample_2022_2023.csv          # Your 2-year sample
‚îú‚îÄ‚îÄ batch_input/
‚îÇ   ‚îî‚îÄ‚îÄ batch_sample_2022_2023.jsonl  # Ready for OpenAI
‚îî‚îÄ‚îÄ results/
    ‚îî‚îÄ‚îÄ phase1_statistics.json        # Cost breakdown
```

---

## Installation

### Prerequisites

- **Python 3.9 or higher**
- **OpenAI API Key** ([Get one here](https://platform.openai.com/api-keys))
- **Hugging Face Token** ([Get one here](https://huggingface.co/settings/tokens))
- **Git** (for version control)

### Step-by-Step Setup

**1. Clone the repository**

```bash
git clone <repository-url>
cd llm_sentiment
```

**2. Create a virtual environment** (recommended)

```bash
# On macOS/Linux:
python3 -m venv venv
source venv/bin/activate

# On Windows:
python -m venv venv
venv\Scripts\activate
```

**3. Install dependencies**

```bash
pip install -r requirements.txt
```

**4. Set up your API keys**

```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your API keys
# On macOS/Linux:
nano .env

# On Windows:
notepad .env
```

Add **both** keys to the `.env` file:
```
OPENAI_API_KEY=sk-your-actual-openai-key-here
HF_TOKEN=hf_your-actual-huggingface-token-here
```

**Where to get tokens:**
- OpenAI: https://platform.openai.com/api-keys
- Hugging Face: https://huggingface.co/settings/tokens (select "Read" access)

**5. Verify installation**

```bash
python src/config.py
```

You should see: `‚úÖ Configuration is ready to use!`

---

## Quick Start

### Run Phase 1 (Two-Step Process)

Phase 1 is split into two scripts for flexibility:

**Step 1: Data Preparation**
```bash
python phase1_data_prep.py
```

This will:
1. Download the ECB-FED speeches dataset (~2-3 minutes first run)
2. Sample speeches from 2022-2023
3. Save sample data to CSV

**Step 2: Batch File Creation**
```bash
python phase1_batch_prep.py
```

This will:
1. Load the sample data (from Step 1)
2. Create batch processing file
3. Show cost comparison

**Why two scripts?**
- Run data prep once, create multiple batch variations
- Iterate on prompts without re-downloading data
- Clearer separation of concerns

**Example Output:**

```
========================================
BATCH PREPARATION COMPLETE ‚úÖ
========================================

üìÅ Files created:
   1. Batch file:   data/batch_input/batch_sample_2022_2023.jsonl
   2. Statistics:   data/results/phase1_statistics.json

üí∞ Cost Estimates:
   Batch API:     $12.50
   Real-time API: $25.00
   Savings:       $12.50 (50% discount)
```

**Legacy:** You can still run `python phase1_demo.py` to do everything in one go.

### Inspect the Results

**View the sample data:**
```bash
# On macOS/Linux:
head -20 data/processed/sample_2022_2023.csv

# On Windows:
type data\processed\sample_2022_2023.csv | more
```

**View cost statistics:**
```bash
cat data/results/phase1_statistics.json
```

---

## Project Structure

```
llm_sentiment/
‚îÇ
‚îú‚îÄ‚îÄ README.md                 # This file
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ .env.example             # Template for API keys
‚îú‚îÄ‚îÄ .gitignore              # Files to exclude from Git
‚îÇ
‚îú‚îÄ‚îÄ phase1_demo.py          # Phase 1 main script
‚îÇ
‚îú‚îÄ‚îÄ src/                    # Source code
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration settings
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py     # Load Hugging Face dataset
‚îÇ   ‚îú‚îÄ‚îÄ batch_builder.py   # Create batch API files
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.py # Submit & monitor batch jobs
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Data files (created when you run)
‚îÇ   ‚îú‚îÄ‚îÄ raw/               # Downloaded datasets
‚îÇ   ‚îú‚îÄ‚îÄ processed/         # Cleaned/sampled data
‚îÇ   ‚îú‚îÄ‚îÄ batch_input/       # Files to upload to OpenAI
‚îÇ   ‚îú‚îÄ‚îÄ batch_output/      # Results from OpenAI
‚îÇ   ‚îî‚îÄ‚îÄ results/           # Final analysis results
‚îÇ
‚îú‚îÄ‚îÄ notebooks/             # Jupyter notebooks (for exploration)
‚îÇ
‚îî‚îÄ‚îÄ config/               # Configuration files
```

---

## For Beginners

### What is a "Batch API"?

Think of it like this:

**Real-time API** (traditional):
- You: "Analyze this speech" ‚Üí OpenAI: "Here's the result" (instant)
- Like ordering fast food: immediate, but you pay full price
- Good for: One or a few speeches

**Batch API**:
- You: "Here are 100 speeches, analyze them all" ‚Üí OpenAI: "I'll work on it and email you when done" (24 hours max)
- Like ordering catering: takes longer, but you get a bulk discount
- Good for: Hundreds or thousands of speeches

### Key Concepts

**Tokens**
- How OpenAI measures text length
- Roughly: 1 token ‚âà 4 characters ‚âà 0.75 words
- Example: "Hello world" ‚âà 2 tokens

**Prompt**
- The instructions you give to GPT
- Like hiring an analyst: the better your instructions, the better the analysis

**JSONL**
- JSON Lines format
- One JSON object per line
- Required format for Batch API

**Sentiment**
- The overall tone or stance
- In central banking: "Hawkish" (tightening) vs "Dovish" (easing)

### Common Issues & Solutions

**Issue**: `OPENAI_API_KEY not found`
- **Solution**: Make sure you created `.env` file and added your API key

**Issue**: `ModuleNotFoundError: No module named 'datasets'`
- **Solution**: Run `pip install -r requirements.txt`

**Issue**: `Permission denied` when running script
- **Solution**: On macOS/Linux, run `chmod +x phase1_demo.py` first

**Issue**: Download is slow
- **Solution**: First download takes time (downloading dataset). Subsequent runs use cached version.

---

## Cost Estimates

### Phase 1 (2 years of data)

Typical costs for 2022-2023 sample (estimates may vary):

| API Type | Input Tokens | Output Tokens | Total Cost |
|----------|-------------|---------------|------------|
| Batch API | 5,000,000 | 1,000,000 | ~$11.25 |
| Real-time API | 5,000,000 | 1,000,000 | ~$22.50 |
| **Savings** | - | - | **~$11.25 (50%)** |

*Based on GPT-4o pricing as of 2024. Actual costs depend on speech length.*

### Full Dataset (1996-2025)

Estimated costs for complete analysis:

- **Batch API**: ~$75-150
- **Real-time API**: ~$150-300
- **Savings**: ~$75-150

**Why the range?**
- Speeches vary in length
- Some years have more speeches than others
- Actual token usage may differ from estimates

### Cost Control Tips

‚úÖ **Always test with Phase 1 first** - See actual costs before scaling up
‚úÖ **Check estimates** - The script shows estimates before uploading
‚úÖ **Use batch API** - Automatic 50% discount
‚úÖ **Monitor usage** - Check your OpenAI dashboard regularly

---

## Documentation

### Module Documentation

Each Python module has detailed documentation:

```python
# To see documentation for a module:
python -c "import src.data_loader; help(src.data_loader.DataLoader)"
```

### Code Comments

Every function includes:
- **Purpose**: What it does
- **Parameters**: What inputs it needs
- **Returns**: What it gives back
- **For beginners** section: Plain English explanation

Example:
```python
def load_from_huggingface(self) -> pd.DataFrame:
    """
    Load the dataset from Hugging Face.

    Returns:
        DataFrame containing all speeches with metadata

    For beginners:
    - This function first checks if we already have the data saved locally
    - If yes, it loads from local file (much faster!)
    - If no, it downloads from Hugging Face and saves for next time
    """
```

### Getting Help

**In the code:**
- Read the comments (lines starting with `#`)
- Read the docstrings (text in `"""triple quotes"""`)
- Look for "For beginners:" sections

**External resources:**
- [OpenAI Batch API Documentation](https://platform.openai.com/docs/guides/batch)
- [Hugging Face Datasets](https://huggingface.co/docs/datasets/)
- [Pandas Tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)

---

## Research Background

### Literature This Project Builds On

1. **Liao et al. (2024)** - Comparison of LLMs for central bank sentiment
2. **IMF (2025)** - Large-scale analysis of 169 central banks
3. **ECB Working Papers** - Hawkish/dovish classification methods
4. **Federal Reserve (2024)** - Using GPT for FOMC minutes analysis

See the full literature review in the project documentation.

### Novel Contributions

This project advances research by:

‚úÖ **Democratization**: Making advanced analysis accessible without expensive training data
‚úÖ **Multi-dimensional**: Extracting 5+ dimensions vs. single hawkish/dovish score
‚úÖ **Cross-country**: Consistent methodology for Fed AND ECB
‚úÖ **Reproducible**: All code and data sources are open

---

## Contributing

This is a research project organized in phases. Each phase has:

1. **Clear objectives** - What we're trying to accomplish
2. **Implementation** - Code to achieve objectives
3. **Validation** - Tests to ensure quality
4. **Pull Request** - Review before moving forward

### Current Phase Checklist

Phase 1:
- [x] Project structure created
- [x] Data loader implemented
- [x] Batch processing modules created
- [x] Cost comparison functional
- [x] Documentation complete
- [ ] Run demo and validate results
- [ ] Create Pull Request
- [ ] Review and merge

---

## License

See [LICENSE](LICENSE) file for details.

---

## Acknowledgments

- **Dataset**: ECB-FED speeches from [istat-ai/ECB-FED-speeches](https://huggingface.co/datasets/istat-ai/ECB-FED-speeches)
- **API**: OpenAI's GPT-4o and Batch API
- **Inspiration**: Academic research on central bank communication analysis

---

## Contact

For questions about this research project, please open an issue on GitHub.

---

**Last Updated**: Phase 1 - January 2025
